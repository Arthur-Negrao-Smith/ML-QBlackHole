{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from load import (file_exists, RAW_FILE, FILE_NAMES, load_dataset, split_dataset)\n",
    "from util.data_keys import Datakeys as dk\n",
    "\n",
    "from os import cpu_count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cores: int | None = cpu_count()\n",
    "CORES: int = 4 if tmp_cores is None else tmp_cores\n",
    "RANDOM_SEED: int = 1137\n",
    "TEST_SIZE: float = 0.2\n",
    "\n",
    "ML_FILE_PATH: str = \"data/ml\"\n",
    "MANIPULATED_PATH: str = \"data/manipulated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_exists(FILE_NAMES[0]):\n",
    "        split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_dict() -> dict:\n",
    "    return {\n",
    "        \"Random Forest\": RandomForestClassifier(62, n_jobs=CORES),\n",
    "        \"Gradient Boost\": GradientBoostingClassifier(),\n",
    "        \"SGD Classifier\": SGDClassifier(),\n",
    "        \"Benoulli NB\": BernoulliNB(),\n",
    "        \"Linear SVC\": LinearSVC(),\n",
    "        \"Gaussian NB\": GaussianNB()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eabfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column in df.columns:\n",
    "        if (column == dk.ATTACK_TYPE.value):\n",
    "            continue\n",
    "\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5dd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_algorithms(models: dict, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "    for name, model in models.items():\n",
    "\n",
    "        start: float = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"{name} fit time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(\n",
    "        columns=[\n",
    "            # string column\n",
    "            dk.INTENSITY.value,\n",
    "\n",
    "            # answer columns\n",
    "            dk.NUMBER_OF_BLACK_HOLES.value,\n",
    "            dk.BLACK_HOLE_SWAP_PROB.value,\n",
    "            dk.TARGETS_PER_BLACK_HOLE.value,\n",
    "\n",
    "            # Constant columns\n",
    "            dk.REQUESTS.value,\n",
    "            dk.PARAMETER.value,\n",
    "            dk.TOPOLOGY.value,\n",
    "            dk.TOTAL_NO_PATHS.value,\n",
    "            dk.NUMBER_OF_NODES.value,\n",
    "\n",
    "            # Redundant features\n",
    "            dk.TOTAL_REQUEST_FAILS.value, # TOTAL_REQUEST_SUCCESS\n",
    "            dk.TOTAL_SWAPPING_FAILS.value, # TOTAL_SWAPPING_FAILS\n",
    "\n",
    "            # feature don't worry\n",
    "            dk.SIMULATION_TIME.value,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df: pd.DataFrame = load_dataset(RAW_FILE)\n",
    "\n",
    "normal_df: pd.DataFrame = all_df.loc[\n",
    "    all_df[dk.NUMBER_OF_BLACK_HOLES.value] == 0\n",
    "].sample(10_000, random_state=RANDOM_SEED)\n",
    "\n",
    "normal_df = clean_up_df(normal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models_with_cross_validation(models: dict, X: pd.DataFrame, y: pd.Series) -> dict[str, dict]:\n",
    "    data: dict = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        start = time.time()\n",
    "        \n",
    "        scoring = {\n",
    "            'accuracy': 'accuracy', \n",
    "            'f1_score': make_scorer(f1_score, average='macro'),\n",
    "            'precision_score': make_scorer(precision_score, zero_division=0),\n",
    "            'recall_score': make_scorer(recall_score),\n",
    "        }\n",
    "\n",
    "        results: dict = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "        total_time = time.time() - start\n",
    "        print(f\"{name} cross time: {total_time}\")\n",
    "        \n",
    "        data[name] = {test_name: result for test_name, result in results.items()}\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58248b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in FILE_NAMES:\n",
    "    current_file_name: str = MANIPULATED_PATH + \"/\" + file_name\n",
    "    print(\"-\"*60)\n",
    "    print(current_file_name)\n",
    "    attack_df: pd.DataFrame = load_dataset(current_file_name)\n",
    "    attack_df = clean_up_df(attack_df)\n",
    "\n",
    "    analyzis_df: pd.DataFrame = pd.concat(objs=[attack_df, normal_df])\n",
    "    analyzis_df = normalize_df(analyzis_df)\n",
    "\n",
    "    X: pd.DataFrame = analyzis_df.drop(columns=dk.ATTACK_TYPE.value)\n",
    "    y: pd.Series = analyzis_df[dk.ATTACK_TYPE.value]\n",
    "\n",
    "    models: dict = get_models_dict()\n",
    "    results: dict[str, dict] = predict_models_with_cross_validation(models, X, y)\n",
    "    \n",
    "    result_mean: dict = {}\n",
    "    mean_score_dict: dict = {}\n",
    "\n",
    "    for model_name, tmp_result in results.items():\n",
    "        result_mean = {}\n",
    "\n",
    "        for name_result, array_result in tmp_result.items():\n",
    "            result_mean[name_result] = array_result.mean()\n",
    "\n",
    "        mean_score_dict[model_name] = result_mean\n",
    "\n",
    "    df_results: pd.DataFrame = pd.DataFrame(mean_score_dict).T\n",
    "    \n",
    "    df_results.reset_index(inplace=True)\n",
    "\n",
    "    df_results = df_results.drop(columns=[\"score_time\", \"fit_time\"])\n",
    "    \n",
    "    df_results.rename(\n",
    "        columns={\n",
    "            'index': 'Model',\n",
    "            \"test_accuracy\": \"Accuracy\",\n",
    "            \"test_f1_score\": \"F1 Score\",\n",
    "            \"test_precision_score\": \"Precision\",\n",
    "            \"test_recall_score\": \"Recall\"\n",
    "        }, \n",
    "        inplace=True\n",
    "        )\n",
    "    \n",
    "    df_results.to_csv(ML_FILE_PATH + \"/\" + file_name, mode=\"w\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
