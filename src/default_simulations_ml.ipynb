{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import Generator\n",
    "\n",
    "from load import (file_exists, RAW_FILE, FILE_NAMES, load_dataset, split_dataset)\n",
    "from util.data_keys import Datakeys as dk\n",
    "\n",
    "from os import cpu_count\n",
    "from typing import Any\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cores: int | None = cpu_count()\n",
    "CORES: int = 4 if tmp_cores is None else tmp_cores\n",
    "RANDOM_SEED: int = 1137\n",
    "RNG: Generator = np.random.default_rng(RANDOM_SEED)\n",
    "TRAIN_SIZE: float = 0.8\n",
    "\n",
    "ML_FILE_PATH: str = \"data/ml\"\n",
    "MANIPULATED_PATH: str = \"data/manipulated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_exists(FILE_NAMES[0]):\n",
    "        split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_dict() -> dict:\n",
    "    return {\n",
    "        \"Random Forest\": RandomForestClassifier,\n",
    "        \"Gradient Boost\": GradientBoostingClassifier,\n",
    "        \"SGD Classifier\": SGDClassifier,\n",
    "        \"Benoulli NB\": BernoulliNB,\n",
    "        \"Linear SVC\": LinearSVC,\n",
    "        \"Gaussian NB\": GaussianNB\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eabfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column in df.columns:\n",
    "        if (column == dk.ATTACK_TYPE.value):\n",
    "            continue\n",
    "\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(\n",
    "        columns=[\n",
    "            # string column\n",
    "            dk.INTENSITY.value,\n",
    "\n",
    "            # answer columns\n",
    "            dk.NUMBER_OF_BLACK_HOLES.value,\n",
    "            dk.BLACK_HOLE_SWAP_PROB.value,\n",
    "            dk.TARGETS_PER_BLACK_HOLE.value,\n",
    "\n",
    "            # Constant columns\n",
    "            dk.REQUESTS.value,\n",
    "            dk.PARAMETER.value,\n",
    "            dk.TOPOLOGY.value,\n",
    "            dk.TOTAL_NO_PATHS.value,\n",
    "            dk.NUMBER_OF_NODES.value,\n",
    "\n",
    "            # Redundant features\n",
    "            dk.TOTAL_REQUEST_FAILS.value, # TOTAL_REQUEST_SUCCESS\n",
    "            dk.TOTAL_SWAPPING_FAILS.value, # TOTAL_SWAPPING_FAILS\n",
    "\n",
    "            # feature don't worry\n",
    "            dk.SIMULATION_TIME.value,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df: pd.DataFrame = load_dataset(RAW_FILE)\n",
    "\n",
    "all_normal_df: pd.DataFrame = all_df.loc[\n",
    "    all_df[dk.NUMBER_OF_BLACK_HOLES.value] == 0\n",
    "].sample(10_000, random_state=RANDOM_SEED)\n",
    "\n",
    "all_normal_df = clean_up_df(all_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea6ba4",
   "metadata": {},
   "source": [
    "### My cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4980a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_validation(models: dict[str, Any], X: pd.DataFrame, y: pd.Series, train_propotion: float, rng: Generator, rounds: int = 5) -> pd.DataFrame:\n",
    "\n",
    "    all_results: list[dict] = []\n",
    "\n",
    "    for model_name, model_constructor in models.items():\n",
    "        start: float = time()\n",
    "        print(f\"Cross validation of the model: {model_name}\")\n",
    "\n",
    "        for _ in range(rounds):\n",
    "            # rng\n",
    "            indices: np.ndarray = rng.permutation(len(X))\n",
    "            limit_point: int = int(len(X) * train_propotion)\n",
    "\n",
    "            # get rng indices\n",
    "            indices_train: np.ndarray = indices[:limit_point]\n",
    "            indices_test: np.ndarray  = indices[limit_point:]\n",
    "\n",
    "            # split data to train and test\n",
    "            x_train: pd.DataFrame = X.iloc[indices_train].copy()\n",
    "            y_train: pd.Series = y.iloc[indices_train].copy()\n",
    "\n",
    "            x_test: pd.DataFrame = X.iloc[indices_test].copy()\n",
    "            y_test: pd.Series = y.iloc[indices_test].copy()\n",
    "\n",
    "            # normalize the data\n",
    "            scaler: StandardScaler = StandardScaler(copy=False)\n",
    "            x_train = scaler.fit_transform(x_train) # type: ignore\n",
    "            # avoid data leaking\n",
    "            x_test = scaler.transform(x_test)       # type: ignore\n",
    "\n",
    "            # fit the model\n",
    "            model: Any = model_constructor()\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            # collect the predict\n",
    "            y_pred: np.ndarray = model.predict(x_test)\n",
    "\n",
    "            # calculate the scores\n",
    "            scores: dict = {\n",
    "                \"Model\": model_name,\n",
    "                \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"F1\": f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "                \"Precision\": precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "                \"Recall\": recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            }\n",
    "\n",
    "            all_results.append(scores)\n",
    " \n",
    "        print(f\"Model {model_name} finish: {time()-start}\")\n",
    "    \n",
    "    df_results: pd.DataFrame = pd.DataFrame(all_results)\n",
    "\n",
    "    mean_result: pd.DataFrame = df_results.groupby(\"Model\").mean(numeric_only=True).reset_index()\n",
    "\n",
    "    return mean_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58248b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in FILE_NAMES:\n",
    "    current_file_name: str = MANIPULATED_PATH + \"/\" + file_name\n",
    "    print(\"-\"*60)\n",
    "    print(current_file_name)\n",
    "\n",
    "    attack_df: pd.DataFrame = load_dataset(current_file_name)\n",
    "    attack_df = clean_up_df(attack_df)\n",
    "\n",
    "    normal_df: pd.DataFrame = all_normal_df.sample(len(attack_df), random_state=RNG)\n",
    "\n",
    "    analyzis_df: pd.DataFrame = pd.concat(objs=[attack_df, normal_df])\n",
    "\n",
    "    X: pd.DataFrame = analyzis_df.drop(columns=dk.ATTACK_TYPE.value)\n",
    "    y: pd.Series = analyzis_df[dk.ATTACK_TYPE.value]\n",
    "\n",
    "    models: dict = get_models_dict()\n",
    "    df_results: pd.DataFrame = my_cross_validation(models, X, y, TRAIN_SIZE, RNG)\n",
    "    \n",
    "    df_results.to_csv(ML_FILE_PATH + \"/\" + file_name, mode=\"w\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
